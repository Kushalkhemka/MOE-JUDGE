# LMSys - Chatbot Arena Conversations Dataset

This dataset contains 33K cleaned conversations with pairwise human preferences. It is collected
from 13K unique IP addresses on the Chatbot Arena from April to June 2023. Each sample includes a
question ID, two model names, their full conversation text in OpenAI API JSON format, the user
vote, the anonymized user ID, the detected language tag, the OpenAI moderation API tag, the
additional toxic tag, and the timestamp. The original dataset and dataset card are available at: https://huggingface.co/datasets/lmsys/chatbot_arena_conversations

Run `python convert.py` to convert the original data into the common format. This will create a
file `data.json` in the current directory.

## Details about the conversion script

This script was generated by including the prompt that is currently used by the LMSys team to
evaluate the models. This can be found here:
https://github.com/lm-sys/FastChat/blob/main/fastchat/llm_judge/data/judge_prompts.jsonl
They ask the "judge model" to output either [[A]], [[B]] or [[C]].

However, in the actual dataset on Huggingface, they have the following labels: "model_a",
"model_b", "tie", "tie (bothbad)".

